{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11313929,"sourceType":"datasetVersion","datasetId":7076613},{"sourceId":232490302,"sourceType":"kernelVersion"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.metrics import mean_squared_error, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom datetime import datetime, timedelta\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Load the data\ndef load_data(filepath):\n    print(\"Loading data...\")\n    df = pd.read_csv(filepath)\n    print(f\"Data loaded with {df.shape[0]} rows and {df.shape[1]} columns\")\n    \n    # Display column names to debug\n    print(f\"Columns in dataset: {df.columns.tolist()}\")\n    \n    return df\n\n# Clean data by removing invalid rows and handling NaN values\ndef clean_data(df):\n    print(\"\\nCleaning data...\")\n    \n    # Count initial NaN values in key columns\n    print(\"NaN values before cleaning:\")\n    for col in ['localtime', 'temperature', 'weather_descriptions', 'wind_speed', 'humidity']:\n        if col in df.columns:\n            print(f\"  {col}: {df[col].isna().sum()} NaN values\")\n    \n    # Remove rows where all values are NaN\n    initial_rows = len(df)\n    df = df.dropna(how='all')\n    print(f\"Removed {initial_rows - len(df)} completely empty rows\")\n    \n    # Drop rows with NaN in critical columns\n    critical_cols = ['localtime', 'temperature']\n    df_clean = df.dropna(subset=critical_cols)\n    print(f\"Removed {len(df) - len(df_clean)} rows with missing datetime or temperature\")\n    \n    # Handle remaining NaNs in numeric columns by imputing with median\n    numeric_cols = ['wind_speed', 'pressure', 'humidity', 'cloudcover', 'feelslike', 'uv_index', 'visibility']\n    for col in numeric_cols:\n        if col in df_clean.columns:\n            nan_count = df_clean[col].isna().sum()\n            if nan_count > 0:\n                median_val = df_clean[col].median()\n                df_clean[col].fillna(median_val, inplace=True)\n                print(f\"Filled {nan_count} NaN values in {col} with median ({median_val:.2f})\")\n    \n    # Handle NaN in categorical columns\n    categorical_cols = ['weather_descriptions', 'wind_dir', 'is_day']\n    for col in categorical_cols:\n        if col in df_clean.columns:\n            nan_count = df_clean[col].isna().sum()\n            if nan_count > 0:\n                mode_val = df_clean[col].mode()[0]\n                df_clean[col].fillna(mode_val, inplace=True)\n                print(f\"Filled {nan_count} NaN values in {col} with mode ({mode_val})\")\n    \n    print(f\"Final clean dataset: {len(df_clean)} rows\")\n    return df_clean\n\n# Process the datetime columns\ndef process_datetime(df):\n    print(\"\\nProcessing datetime columns...\")\n    \n    # Check format of localtime column\n    print(f\"Sample localtime values: {df['localtime'].head(3).tolist()}\")\n    \n    # Convert localtime to datetime - try multiple formats\n    try:\n        df['localtime'] = pd.to_datetime(df['localtime'], errors='coerce')\n    except:\n        print(\"Standard datetime conversion failed, trying multiple formats...\")\n    \n    # Handle NaT values by trying alternative formats\n    nat_mask = df['localtime'].isna()\n    if nat_mask.sum() > 0:\n        # Try different formats for parsing dates\n        formats = ['%m/%d/%Y %H:%M:%S', '%m/%d/%Y %H:%M', '%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M']\n        for fmt in formats:\n            if nat_mask.sum() > 0:\n                df.loc[nat_mask, 'localtime'] = pd.to_datetime(\n                    df.loc[nat_mask, 'localtime'], \n                    format=fmt, \n                    errors='coerce'\n                )\n                nat_mask = df['localtime'].isna()\n                print(f\"After trying format {fmt}: {nat_mask.sum()} invalid dates remain\")\n    \n    # Extract datetime features\n    df['hour'] = df['localtime'].dt.hour\n    df['dayofweek'] = df['localtime'].dt.dayofweek\n    df['day'] = df['localtime'].dt.day\n    df['month'] = df['localtime'].dt.month\n    df['year'] = df['localtime'].dt.year\n    \n    # Convert is_day to numeric\n    if 'is_day' in df.columns:\n        df['is_day_numeric'] = df['is_day'].apply(lambda x: 1 if str(x).lower() == 'yes' else 0)\n    \n    # Print date range\n    min_date = df['localtime'].min()\n    max_date = df['localtime'].max()\n    print(f\"Clean date range: {min_date} to {max_date}\")\n    \n    # Count records by year\n    year_counts = df['year'].value_counts().sort_index()\n    print(\"Records by year:\")\n    print(year_counts)\n    \n    return df\n\n# Process weather descriptions\ndef process_weather_descriptions(df):\n    print(\"\\nProcessing weather descriptions...\")\n    \n    if 'weather_descriptions' not in df.columns:\n        print(\"weather_descriptions column not found in dataset\")\n        return df\n    \n    # Make a copy of the original column for debugging\n    df['original_descriptions'] = df['weather_descriptions'].copy()\n    \n    # Handle various formats\n    try:\n        # Check a few sample values\n        sample_vals = df['weather_descriptions'].dropna().sample(min(5, len(df))).tolist()\n        print(f\"Sample weather_descriptions values: {sample_vals}\")\n        \n        # Try to detect list format based on first non-null value\n        first_val = df['weather_descriptions'].dropna().iloc[0]\n        \n        if isinstance(first_val, str):\n            if first_val.startswith('[') and ']' in first_val:\n                # Handle JSON-like strings\n                print(\"Detected JSON-like strings in weather_descriptions\")\n                \n                # Function to safely parse string representations of lists\n                def parse_weather_desc(x):\n                    if pd.isna(x):\n                        return [\"Unknown\"]\n                    if isinstance(x, list):\n                        return x\n                    if isinstance(x, str):\n                        try:\n                            if x.startswith('[') and ']' in x:\n                                # Remove any escape characters and parse\n                                clean_x = x.replace('\\\\', '')\n                                parsed = eval(clean_x)\n                                if isinstance(parsed, list):\n                                    return parsed\n                                else:\n                                    return [str(parsed)]\n                            else:\n                                return [x]\n                        except:\n                            return [x]\n                    return [\"Unknown\"]\n                \n                # Apply parsing\n                df['parsed_descriptions'] = df['weather_descriptions'].apply(parse_weather_desc)\n                \n                # Extract first description\n                df['weather_desc'] = df['parsed_descriptions'].apply(\n                    lambda x: x[0] if isinstance(x, list) and len(x) > 0 else \"Unknown\")\n            else:\n                # Simple string values\n                print(\"Detected plain strings in weather_descriptions\")\n                df['weather_desc'] = df['weather_descriptions']\n        elif isinstance(first_val, list):\n            # Already in list format\n            print(\"Detected list objects in weather_descriptions\")\n            df['weather_desc'] = df['weather_descriptions'].apply(\n                lambda x: x[0] if isinstance(x, list) and len(x) > 0 else \n                        (x if not pd.isna(x) else \"Unknown\"))\n        else:\n            # Default case\n            print(f\"Unknown format in weather_descriptions (type: {type(first_val)})\")\n            df['weather_desc'] = df['weather_descriptions'].astype(str).apply(\n                lambda x: x if not pd.isna(x) and x != 'nan' else \"Unknown\")\n        \n        # Verify results\n        unique_descs = df['weather_desc'].nunique()\n        top_descs = df['weather_desc'].value_counts().head(5).to_dict()\n        print(f\"Unique weather descriptions: {unique_descs}\")\n        print(f\"Top weather_desc values: {top_descs}\")\n        \n    except Exception as e:\n        print(f\"Error processing weather descriptions: {e}\")\n        # Create a default weather_desc column\n        df['weather_desc'] = \"Unknown\"\n    \n    return df\n\n# One-hot encode categorical variables\ndef encode_categorical(df):\n    print(\"\\nEncoding categorical variables...\")\n    \n    # Save a copy of the weather_desc column before encoding\n    if 'weather_desc' in df.columns:\n        weather_desc_original = df['weather_desc'].copy()\n    else:\n        weather_desc_original = None\n        print(\"Warning: weather_desc column not found\")\n    \n    # Check if the columns exist before encoding\n    categorical_cols = []\n    if 'weather_desc' in df.columns:\n        categorical_cols.append('weather_desc')\n    \n    if 'wind_dir' in df.columns:\n        categorical_cols.append('wind_dir')\n    else:\n        print(\"Warning: wind_dir column not found\")\n    \n    # One-hot encode categorical variables\n    if categorical_cols:\n        # For weather descriptions, limit to top N most common to avoid too many columns\n        if 'weather_desc' in categorical_cols:\n            top_n = 15  # Adjust as needed\n            top_values = df['weather_desc'].value_counts().head(top_n).index\n            print(f\"One-hot encoding only the top {top_n} weather descriptions\")\n            \n            # Create \"other\" category for less common values\n            df['weather_desc'] = df['weather_desc'].apply(\n                lambda x: x if x in top_values else 'Other')\n        \n        # Encode categories\n        df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=False)\n        encoded_cols = [col for col in df_encoded.columns if any(col.startswith(c + '_') for c in categorical_cols)]\n        print(f\"Encoded {len(categorical_cols)} categorical variables into {len(encoded_cols)} dummy variables\")\n        \n        # Restore the original weather_desc column for model training\n        if weather_desc_original is not None:\n            df_encoded['weather_desc'] = weather_desc_original\n    else:\n        df_encoded = df.copy()\n        print(\"No categorical variables to encode\")\n    \n    return df_encoded\n\n# Prepare features for modeling\ndef prepare_features(df):\n    print(\"\\nPreparing features for modeling...\")\n    \n    # Features for temperature prediction\n    numeric_features = ['hour', 'dayofweek', 'month', 'year']\n    \n    # Add additional features if they exist\n    for col in ['wind_speed', 'humidity', 'pressure', 'cloudcover', 'feelslike', 'uv_index', 'visibility', 'is_day_numeric']:\n        if col in df.columns:\n            numeric_features.append(col)\n    \n    print(f\"Selected features: {numeric_features}\")\n    return numeric_features\n\n# Train temperature prediction model\ndef train_temp_model(df, features):\n    print(\"\\nTraining temperature prediction model...\")\n    \n    # Select only rows with valid temperature data\n    df_temp = df.dropna(subset=['temperature'])\n    \n    # Select valid features (drop any that might have become NaN)\n    X = df_temp[features].dropna(axis=1)\n    available_features = X.columns.tolist()\n    print(f\"Using features: {available_features}\")\n    \n    y = df_temp['temperature']\n    \n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    # Train model\n    temp_model = RandomForestRegressor(n_estimators=100, random_state=42)\n    temp_model.fit(X_train, y_train)\n    \n    # Evaluate model\n    y_pred = temp_model.predict(X_test)\n    mse = mean_squared_error(y_test, y_pred)\n    rmse = np.sqrt(mse)\n    print(f\"Temperature MSE: {mse:.4f}\")\n    print(f\"Temperature RMSE: {rmse:.4f} degrees\")\n    \n    # Feature importance\n    feature_importance = pd.DataFrame({\n        'Feature': available_features,\n        'Importance': temp_model.feature_importances_\n    }).sort_values('Importance', ascending=False)\n    \n    print(\"\\nTop 5 most important features for temperature prediction:\")\n    print(feature_importance.head(5))\n    \n    return temp_model, available_features\n\n# Train weather description prediction model\ndef train_weather_desc_model(df):\n    print(\"\\nTraining weather description model...\")\n    \n    # Check if weather_desc column exists\n    if 'weather_desc' not in df.columns:\n        print(\"Cannot train weather description model: weather_desc column not found\")\n        return None, None, None\n    \n    # Select rows with valid weather descriptions\n    df_weather = df.dropna(subset=['weather_desc'])\n    df_weather = df_weather[df_weather['weather_desc'] != 'Unknown']\n    \n    # Count unique weather descriptions\n    unique_descs = df_weather['weather_desc'].nunique()\n    print(f\"Found {unique_descs} unique weather descriptions for modeling\")\n    \n    if unique_descs <= 1:\n        print(\"Need at least 2 unique weather descriptions to train classifier\")\n        return None, None, None\n    \n    # Features for weather prediction\n    features = ['hour', 'dayofweek', 'month', 'year']\n    for col in ['temperature', 'wind_speed', 'humidity', 'pressure', 'cloudcover', 'is_day_numeric']:\n        if col in df_weather.columns:\n            features.append(col)\n    \n    # Select valid features\n    X = df_weather[features].dropna(axis=1)\n    available_features = X.columns.tolist()\n    y = df_weather['weather_desc']\n    \n    # Check if we have enough data\n    if len(X) < 20:\n        print(f\"Insufficient data ({len(X)} rows) to train weather model\")\n        return None, None, None\n    \n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    print(f\"Training weather model on {len(X_train)} samples with {len(available_features)} features\")\n    \n    # Train model\n    weather_model = RandomForestClassifier(n_estimators=100, random_state=42)\n    weather_model.fit(X_train, y_train)\n    \n    # Evaluate model\n    y_pred = weather_model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"Weather Description Accuracy: {accuracy:.4f}\")\n    \n    # Class distribution\n    class_dist = y.value_counts().head(5)\n    print(\"\\nTop 5 weather description classes:\")\n    print(class_dist)\n    \n    return weather_model, available_features, df_weather['weather_desc'].unique()\n\n# Generate features for prediction\ndef generate_future_features(target_date, df, temp_features, weather_features):\n    print(f\"\\nGenerating features for future date: {target_date}\")\n\n    # Create a DataFrame with a single row for the target date\n    future_data = pd.DataFrame({\n        'localtime': [target_date],\n        'hour': [target_date.hour],\n        'dayofweek': [target_date.weekday()],  # Changed from dayofweek to weekday()\n        'day': [target_date.day],\n        'month': [target_date.month],\n        'year': [target_date.year],\n    })\n\n    # Add other required columns with default values\n    numeric_cols = ['wind_speed', 'humidity', 'pressure', 'cloudcover',\n                    'feelslike', 'uv_index', 'visibility']\n\n    # Use average values from the dataset for the same month and hour\n    for col in numeric_cols:\n        if col in df.columns:\n            # Get average for same month and hour\n            mask = (df['month'] == target_date.month) & (df['hour'] == target_date.hour)\n            avg_value = df.loc[mask, col].mean()\n\n            # If no data for same month/hour, use overall average\n            if pd.isna(avg_value):\n                avg_value = df[col].mean()\n\n            future_data[col] = avg_value\n\n    # Handle is_day based on hour\n    future_data['is_day'] = 'yes' if 6 <= target_date.hour <= 18 else 'no'\n    future_data['is_day_numeric'] = 1 if future_data['is_day'].iloc[0] == 'yes' else 0\n\n    # Return the right subset of features for each model\n    temp_future = future_data[temp_features].copy() if temp_features else None\n\n    # Predict temperature and add it to future_data\n    if temp_future is not None and 'temperature' in weather_features:\n        temp_model, available_temp_features = train_temp_model(df, temp_features)\n        predicted_temp = temp_model.predict(temp_future)[0]\n        future_data['temperature'] = predicted_temp\n\n    weather_future = future_data[weather_features].copy() if weather_features else None\n\n    return temp_future, weather_future\n\n# Find historical temperatures for same day and hour across years\ndef get_historical_temps(df, target_date):\n    month = target_date.month\n    day = target_date.day\n    hour = target_date.hour\n    \n    print(f\"\\nFinding historical temperatures for {month}/{day} at {hour}:00\")\n    print(f\"Filtering from {len(df)} total records\")\n    \n    # Check for strict matches first (same month and day)\n    month_day_matches = df[(df['month'] == month) & (df['day'] == day)]\n    print(f\"Found {len(month_day_matches)} records with month={month}, day={day}\")\n    \n    historical_temps = {}\n    historical_data = {}  # Store more details for visualization\n    \n    # Check data for each year from 2022 to 2024\n    for year in range(2022, 2025):\n        print(f\"Searching for data from year {year}...\")\n        year_data = month_day_matches[month_day_matches['year'] == year]\n        \n        if not year_data.empty:\n            print(f\"  Found {len(year_data)} records for {year}\")\n            \n            # Try exact hour match first\n            hour_match = year_data[year_data['hour'] == hour]\n            \n            if not hour_match.empty:\n                temp = hour_match['temperature'].iloc[0]\n                temp_row = hour_match.iloc[0]\n                historical_temps[year] = temp\n                historical_data[year] = {\n                    'temperature': temp,\n                    'humidity': temp_row.get('humidity', None),\n                    'wind_speed': temp_row.get('wind_speed', None),\n                    'datetime': temp_row['localtime'],\n                    'match_type': 'exact'\n                }\n                print(f\"  Exact match found for {year} at hour {hour}: temp = {temp}\")\n            else:\n                # If no exact hour match, try closest hour\n                if len(year_data) > 0:\n                    # Calculate hour difference\n                    year_data['hour_diff'] = abs(year_data['hour'] - hour)\n                    closest_match = year_data.loc[year_data['hour_diff'].idxmin()]\n                    temp = closest_match['temperature']\n                    closest_hour = closest_match['hour']\n                    historical_temps[year] = temp\n                    historical_data[year] = {\n                        'temperature': temp,\n                        'humidity': closest_match.get('humidity', None),\n                        'wind_speed': closest_match.get('wind_speed', None),\n                        'datetime': closest_match['localtime'],\n                        'match_type': f'closest hour ({closest_hour})'\n                    }\n                    print(f\"  Closest match for {year} at hour {closest_hour}: temp = {temp}\")\n                else:\n                    historical_temps[year] = None\n                    print(f\"  No data for {year} on {month}/{day}\")\n        else:\n            # If no exact day match, look for closest day in same month and year\n            month_year_data = df[(df['month'] == month) & (df['year'] == year)]\n            if not month_year_data.empty:\n                # Find closest day\n                month_year_data['day_diff'] = abs(month_year_data['day'] - day)\n                closest_day_match = month_year_data.loc[month_year_data['day_diff'].idxmin()]\n                temp = closest_day_match['temperature']\n                closest_day = closest_day_match['day']\n                historical_temps[year] = temp\n                historical_data[year] = {\n                    'temperature': temp,\n                    'humidity': closest_day_match.get('humidity', None),\n                    'wind_speed': closest_day_match.get('wind_speed', None),\n                    'datetime': closest_day_match['localtime'],\n                    'match_type': f'closest day ({month}/{closest_day})'\n                }\n                print(f\"  Found closest day for {year}: {month}/{closest_day}, temp = {temp}\")\n            else:\n                historical_temps[year] = None\n                print(f\"  No data for {year} in month {month}\")\n    \n    return historical_temps, historical_data\n\n# Visualize temperature trends\ndef visualize_temperatures(historical_data, predicted_temp, target_date):\n    print(\"\\nCreating temperature visualization...\")\n    \n    # Set up the figure\n    plt.figure(figsize=(12, 8))\n    \n    # Plot historical temperatures\n    years = []\n    temps = []\n    markers = []\n    labels = []\n    \n    for year in range(2022, 2025):\n        if year in historical_data and historical_data[year].get('temperature') is not None:\n            years.append(year)\n            temps.append(historical_data[year]['temperature'])\n            \n            # Use different markers based on match type\n            if historical_data[year]['match_type'] == 'exact':\n                markers.append('o')  # Circle for exact match\n            elif 'closest hour' in historical_data[year]['match_type']:\n                markers.append('s')  # Square for closest hour\n            else:\n                markers.append('^')  # Triangle for closest day\n            \n            labels.append(f\"{year} ({historical_data[year]['match_type']})\")\n    \n    # Add prediction for future year\n    years.append(2025)\n    temps.append(predicted_temp)\n    markers.append('*')  # Star for prediction\n    labels.append(\"2025 (Predicted)\")\n    \n    # Create the plot\n    for i in range(len(years)):\n        plt.scatter(years[i], temps[i], marker=markers[i], s=150, label=labels[i])\n    \n    # Add trend line if we have at least 2 data points\n    if len(years) >= 2:\n        z = np.polyfit(years, temps, 1)\n        p = np.poly1d(z)\n        plt.plot(years, p(years), \"r--\", alpha=0.7)\n    \n    # Connect the points\n    plt.plot(years, temps, 'b-', alpha=0.5)\n    \n    # Add labels and title\n    month_name = target_date.strftime('%B')\n    plt.xlabel('Year', fontsize=12)\n    plt.ylabel('Temperature (°F)', fontsize=12)\n    plt.title(f'Temperature Trend for {month_name} {target_date.day} at {target_date.hour}:00', fontsize=14)\n    \n    # Customize y-axis to show meaningful range\n    min_temp = min(temps) - 5\n    max_temp = max(temps) + 5\n    plt.ylim(min_temp, max_temp)\n    \n    # Add grid and legend\n    plt.grid(True, alpha=0.3)\n    plt.legend(fontsize=10)\n    \n    # Add text annotations with additional data\n    for i, year in enumerate(years):\n        if year < 2025 and 'humidity' in historical_data.get(year, {}):\n            humidity = historical_data[year].get('humidity')\n            wind = historical_data[year].get('wind_speed')\n            annotation = f\"Humid: {humidity:.1f}%\"\n            if wind is not None:\n                annotation += f\"\\nWind: {wind:.1f}\"\n            plt.annotate(annotation, (year, temps[i]), \n                         textcoords=\"offset points\", \n                         xytext=(0,10), \n                         ha='center',\n                         fontsize=8)\n    \n    # Save the figure\n    plt.tight_layout()\n    plt.savefig('temperature_trend.png')\n    print(\"Visualization saved as 'temperature_trend.png'\")\n    plt.close()\n\n# Get user input for target date\ndef get_target_date():\n    while True:\n        try:\n            # Get current date for default values\n            now = datetime.now()\n            \n            # Ask for date input\n            print(\"\\n==== Target Date Selection ====\")\n            print(\"Enter the date you want to analyze/predict:\")\n            \n            year_input = input(f\"Year (2022-2025) [default: {now.year}]: \").strip()\n            year = int(year_input) if year_input else now.year\n            \n            month_input = input(f\"Month (1-12) [default: {now.month}]: \").strip()\n            month = int(month_input) if month_input else now.month\n            \n            day_input = input(f\"Day (1-31) [default: {now.day}]: \").strip()\n            day = int(day_input) if day_input else now.day\n            \n            hour_input = input(\"Hour (0-23) [default: 12]: \").strip() \n            hour = int(hour_input) if hour_input else 12\n            \n            # Validate inputs\n            if not (2022 <= year <= 2025):\n                print(\"Year must be between 2022 and 2025\")\n                continue\n                \n            if not (1 <= month <= 12):\n                print(\"Month must be between 1 and 12\")\n                continue\n                \n            if not (1 <= day <= 31):\n                print(\"Day must be between 1 and 31\")\n                continue\n                \n            if not (0 <= hour <= 23):\n                print(\"Hour must be between 0 and 23\")\n                continue\n            \n            # Try to create a valid date\n            try:\n                target_date = datetime(year, month, day, hour, 0)\n                print(f\"\\nSelected date: {target_date.strftime('%Y-%m-%d %H:%M')}\")\n                return target_date\n            except ValueError as e:\n                print(f\"Invalid date: {e}\")\n                continue\n                \n        except ValueError:\n            print(\"Please enter valid numbers\")\n\n# Main function\ndef main():\n    # File path to your CSV\n    file_path = '/kaggle/input/kent-weather-2022-current/kent_weather.csv'  # Update this to your actual file path\n    \n    # Load and process data\n    df_raw = load_data(file_path)\n    df_clean = clean_data(df_raw)\n    df = process_datetime(df_clean)\n    df = process_weather_descriptions(df)\n    df_encoded = encode_categorical(df)\n    \n    # Prepare features and train models\n    temp_features = prepare_features(df_encoded)\n    temp_model, available_temp_features = train_temp_model(df_encoded, temp_features)\n    weather_model, available_weather_features, weather_classes = train_weather_desc_model(df_encoded)\n    \n    # Get target date from user\n    target_date = get_target_date()\n    print(f\"Future time: {target_date}\")\n    \n    # Generate features for the future date\n    temp_future, weather_future = generate_future_features(target_date, df, \n                                                         available_temp_features, \n                                                         available_weather_features)\n    \n    # Predict temperature\n    predicted_temp = None\n    if temp_model is not None and temp_future is not None:\n        predicted_temp = temp_model.predict(temp_future)[0]\n        print(f\"\\nPredicted Temperature for {target_date}: {predicted_temp:.2f}°F\")\n    else:\n        print(\"Unable to predict temperature\")\n    \n    # Predict weather description\n    if weather_model is not None and weather_future is not None:\n        try:\n            predicted_weather = weather_model.predict(weather_future)[0]\n            print(f\"Predicted Weather Description for {target_date}: [\\\"{predicted_weather}\\\"]\")\n            \n            # Get prediction probabilities\n            proba = weather_model.predict_proba(weather_future)[0]\n            top_indices = proba.argsort()[-3:][::-1]  # Top 3 predictions\n            \n            print(\"\\nTop 3 possible weather conditions:\")\n            for i in top_indices:\n                weather_type = weather_model.classes_[i]\n                probability = proba[i] * 100\n                print(f\"  - {weather_type}: {probability:.1f}%\")\n        except Exception as e:\n            print(f\"Error predicting weather: {e}\")\n    else:\n        print(\"Weather description model not available\")\n    \n    # Get historical temperatures\n    historical_temps, historical_data = get_historical_temps(df, target_date)\n    \n    # Display results\n    print(f\"\\nTemperatures for {target_date.month}/{target_date.day} at {target_date.hour}:{target_date.minute}:\")\n    for year in range(2022, 2025):\n        if year in historical_temps and historical_temps[year] is not None:\n            match_type = \"\"\n            if year in historical_data:\n                match_type = f\" ({historical_data[year]['match_type']})\"\n            print(f\"{year}: {historical_temps[year]:.2f}°F{match_type}\")\n        else:\n            print(f\"{year}: No data found\")\n    \n    if predicted_temp is not None:\n        print(f\"2025 (Predicted): {predicted_temp:.2f}°F\")\n    \n    # Create visualization\n    if predicted_temp is not None:\n        visualize_temperatures(historical_data, predicted_temp, target_date)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-17T21:54:25.104913Z","iopub.execute_input":"2025-04-17T21:54:25.105222Z"}},"outputs":[{"name":"stdout","text":"Loading data...\nData loaded with 4224 rows and 23 columns\nColumns in dataset: ['Country', 'State', 'City', 'Lat', 'Lon', 'localtime', 'utc_offset', 'observation_time', 'temperature', 'weathe_code', 'weather_icons', 'weather_descriptions', 'wind_speed', 'wind_degree', 'wind_dir', 'pressure', 'precip', 'humidity', 'cloudcover', 'feelslike', 'uv_index', 'visibility', 'is_day']\n\nCleaning data...\nNaN values before cleaning:\n  localtime: 285 NaN values\n  temperature: 285 NaN values\n  weather_descriptions: 285 NaN values\n  wind_speed: 285 NaN values\n  humidity: 285 NaN values\nRemoved 285 completely empty rows\nRemoved 0 rows with missing datetime or temperature\nFinal clean dataset: 3939 rows\n\nProcessing datetime columns...\nSample localtime values: ['1/18/2025 16:58', '1/18/2025 10:59', '1/18/2025 4:58']\nClean date range: 2022-04-26 00:33:00 to 2025-04-06 23:59:00\nRecords by year:\nyear\n2022     911\n2023    1447\n2024    1277\n2025     304\nName: count, dtype: int64\n\nProcessing weather descriptions...\nSample weather_descriptions values: ['[\"Overcast\"]', '[\"Overcast\"]', '[\"Sunny\"]', '[\"Clear\"]', '[\"Clear\"]']\nDetected JSON-like strings in weather_descriptions\nUnique weather descriptions: 45\nTop weather_desc values: {'Overcast': 1109, 'Sunny': 833, 'Clear': 804, 'Partly cloudy': 761, 'Light Rain': 64}\n\nEncoding categorical variables...\nOne-hot encoding only the top 15 weather descriptions\nEncoded 2 categorical variables into 32 dummy variables\n\nPreparing features for modeling...\nSelected features: ['hour', 'dayofweek', 'month', 'year', 'wind_speed', 'humidity', 'pressure', 'cloudcover', 'feelslike', 'uv_index', 'visibility', 'is_day_numeric']\n\nTraining temperature prediction model...\nUsing features: ['hour', 'dayofweek', 'month', 'year', 'wind_speed', 'humidity', 'pressure', 'cloudcover', 'feelslike', 'uv_index', 'visibility', 'is_day_numeric']\nTemperature MSE: 1.3592\nTemperature RMSE: 1.1658 degrees\n\nTop 5 most important features for temperature prediction:\n      Feature  Importance\n8   feelslike    0.992198\n4  wind_speed    0.003006\n5    humidity    0.001470\n6    pressure    0.000907\n9    uv_index    0.000619\n\nTraining weather description model...\nFound 45 unique weather descriptions for modeling\nTraining weather model on 3151 samples with 10 features\nWeather Description Accuracy: 0.9150\n\nTop 5 weather description classes:\nweather_desc\nOvercast         1109\nSunny             833\nClear             804\nPartly cloudy     761\nLight Rain         64\nName: count, dtype: int64\n\n==== Target Date Selection ====\nEnter the date you want to analyze/predict:\n","output_type":"stream"}],"execution_count":null}]}